{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn3R5pdHiMww",
        "outputId": "a71b7b08-1ba6-445f-c57b-143ac7814b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cuda\n",
            "  Processed 0/1943 ...\n",
            "  Processed 1000/1943 ...\n",
            "\n",
            "[Data Ready] total_len=1943\n",
            "\n",
            "=== PHASE 2 CONFIG ===\n",
            "N_FOLDS=5 | BlockGap=0min (0 segs)\n",
            "FoldLen=388 segs (~64.67 min)\n",
            "TrainDur=10min (60 segs) | TestDur=5min (30 segs)\n",
            "TimeGap sweep (min): [0, 5, 10, 15]\n",
            "ValFracInTrain=0.20\n",
            "\n",
            "===============================\n",
            " TimeGap = 0 min\n",
            "===============================\n",
            "\n",
            "[Fold 1] fold=(0,388) | train=(298,358) | test=(358,388)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=1.4385 | SD=1.7433\n",
            "  DBP: MAE=0.7990 | SD=1.0108\n",
            "  elapsed: 11.7s\n",
            "\n",
            "[Fold 2] fold=(388,776) | train=(686,746) | test=(746,776)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=4.6554 | SD=5.5065\n",
            "  DBP: MAE=3.3579 | SD=3.2262\n",
            "  elapsed: 4.8s\n",
            "\n",
            "[Fold 3] fold=(776,1164) | train=(1074,1134) | test=(1134,1164)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=1.8334 | SD=2.0012\n",
            "  DBP: MAE=1.0361 | SD=1.3582\n",
            "  elapsed: 5.3s\n",
            "\n",
            "[Fold 4] fold=(1164,1552) | train=(1462,1522) | test=(1522,1552)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=3.3943 | SD=1.4474\n",
            "  DBP: MAE=2.0387 | SD=0.8061\n",
            "  elapsed: 4.6s\n",
            "\n",
            "[Fold 5] fold=(1552,1940) | train=(1850,1910) | test=(1910,1940)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=2.8520 | SD=3.3109\n",
            "  DBP: MAE=1.4282 | SD=1.8241\n",
            "  elapsed: 5.4s\n",
            "\n",
            "--- TimeGap 0 min SUMMARY ---\n",
            "ValidFolds: 5/5\n",
            "Avg SBP: MAE=2.8347 | SD=2.8019\n",
            "Avg DBP: MAE=1.7320 | SD=1.6451\n",
            "Elapsed for this gap: 31.8s\n",
            "\n",
            "===============================\n",
            " TimeGap = 5 min\n",
            "===============================\n",
            "\n",
            "[Fold 1] fold=(0,388) | train=(268,328) | test=(358,388)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=2.0063 | SD=1.6220\n",
            "  DBP: MAE=0.6959 | SD=0.9466\n",
            "  elapsed: 4.6s\n",
            "\n",
            "[Fold 2] fold=(388,776) | train=(656,716) | test=(746,776)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=10.0719 | SD=1.6954\n",
            "  DBP: MAE=5.9858 | SD=1.0688\n",
            "  elapsed: 4.5s\n",
            "\n",
            "[Fold 3] fold=(776,1164) | train=(1044,1104) | test=(1134,1164)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=6.9885 | SD=2.2175\n",
            "  DBP: MAE=2.8578 | SD=1.5115\n",
            "  elapsed: 6.5s\n",
            "\n",
            "[Fold 4] fold=(1164,1552) | train=(1432,1492) | test=(1522,1552)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=5.4960 | SD=1.7418\n",
            "  DBP: MAE=2.7963 | SD=0.9689\n",
            "  elapsed: 4.5s\n",
            "\n",
            "[Fold 5] fold=(1552,1940) | train=(1820,1880) | test=(1910,1940)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=4.3508 | SD=3.1507\n",
            "  DBP: MAE=4.1471 | SD=1.3657\n",
            "  elapsed: 5.1s\n",
            "\n",
            "--- TimeGap 5 min SUMMARY ---\n",
            "ValidFolds: 5/5\n",
            "Avg SBP: MAE=5.7827 | SD=2.0855\n",
            "Avg DBP: MAE=3.2966 | SD=1.1723\n",
            "Elapsed for this gap: 25.1s\n",
            "\n",
            "===============================\n",
            " TimeGap = 10 min\n",
            "===============================\n",
            "\n",
            "[Fold 1] fold=(0,388) | train=(238,298) | test=(358,388)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=4.0078 | SD=1.6064\n",
            "  DBP: MAE=1.0763 | SD=1.2846\n",
            "  elapsed: 5.0s\n",
            "\n",
            "[Fold 2] fold=(388,776) | train=(626,686) | test=(746,776)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=10.7489 | SD=1.5181\n",
            "  DBP: MAE=5.6175 | SD=0.9868\n",
            "  elapsed: 4.9s\n",
            "\n",
            "[Fold 3] fold=(776,1164) | train=(1014,1074) | test=(1134,1164)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=8.3416 | SD=3.2827\n",
            "  DBP: MAE=3.4107 | SD=1.8695\n",
            "  elapsed: 5.6s\n",
            "\n",
            "[Fold 4] fold=(1164,1552) | train=(1402,1462) | test=(1522,1552)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=12.1088 | SD=1.0455\n",
            "  DBP: MAE=5.9460 | SD=0.6409\n",
            "  elapsed: 4.6s\n",
            "\n",
            "[Fold 5] fold=(1552,1940) | train=(1790,1850) | test=(1910,1940)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=9.6026 | SD=2.8114\n",
            "  DBP: MAE=7.0981 | SD=1.3053\n",
            "  elapsed: 4.5s\n",
            "\n",
            "--- TimeGap 10 min SUMMARY ---\n",
            "ValidFolds: 5/5\n",
            "Avg SBP: MAE=8.9619 | SD=2.0528\n",
            "Avg DBP: MAE=4.6297 | SD=1.2174\n",
            "Elapsed for this gap: 24.6s\n",
            "\n",
            "===============================\n",
            " TimeGap = 15 min\n",
            "===============================\n",
            "\n",
            "[Fold 1] fold=(0,388) | train=(208,268) | test=(358,388)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=3.5579 | SD=2.5982\n",
            "  DBP: MAE=1.2809 | SD=1.5249\n",
            "  elapsed: 5.7s\n",
            "\n",
            "[Fold 2] fold=(388,776) | train=(596,656) | test=(746,776)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=4.3445 | SD=2.3196\n",
            "  DBP: MAE=2.9382 | SD=1.4473\n",
            "  elapsed: 4.5s\n",
            "\n",
            "[Fold 3] fold=(776,1164) | train=(984,1044) | test=(1134,1164)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=7.9007 | SD=3.5256\n",
            "  DBP: MAE=2.2123 | SD=1.9539\n",
            "  elapsed: 5.0s\n",
            "\n",
            "[Fold 4] fold=(1164,1552) | train=(1372,1432) | test=(1522,1552)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=8.2649 | SD=0.9248\n",
            "  DBP: MAE=4.0378 | SD=0.5769\n",
            "  elapsed: 5.1s\n",
            "\n",
            "[Fold 5] fold=(1552,1940) | train=(1760,1820) | test=(1910,1940)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=7.3115 | SD=2.8308\n",
            "  DBP: MAE=6.7884 | SD=1.4131\n",
            "  elapsed: 4.5s\n",
            "\n",
            "--- TimeGap 15 min SUMMARY ---\n",
            "ValidFolds: 5/5\n",
            "Avg SBP: MAE=6.2759 | SD=2.4398\n",
            "Avg DBP: MAE=3.4515 | SD=1.3832\n",
            "Elapsed for this gap: 24.7s\n",
            "\n",
            "[Phase2 Done] Total elapsed: 106.2s\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Phase 2 â€” 5-blocked time-wise CV (p043774)\n",
        "#  - BlockGap = 0 (contiguous 5 folds)\n",
        "#  - Sweep TimeGap_min: [0, 5, 10, 15]\n",
        "#  - TrainDur_min = 10 (fixed)\n",
        "#  - TestDur_min  = 5  (fixed; last 5 min of each fold)\n",
        "#  - Within each fold:\n",
        "#       Test  = last 5 minutes of the fold\n",
        "#       Train = 10 minutes ending at (test_start - time_gap)\n",
        "#       Val   = last 20% of TRAIN (time-aware, contiguous; no gap)\n",
        "#  - Input: PPG_F only (already per-segment min-max 0~1)\n",
        "#  - Label scaling: TRAIN-ONLY per fold (no future leakage)\n",
        "#  - Report:\n",
        "#       * per-fold MAE/SD for SBP/DBP\n",
        "#       * per-gap average across valid folds (mean of fold metrics)\n",
        "#  - No CSV saving\n",
        "# ============================================================\n",
        "\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import h5py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.integrate import trapezoid\n",
        "\n",
        "# ==========================================\n",
        "# [0] Experiment settings\n",
        "# ==========================================\n",
        "MAT_FILE = \"/content/drive/MyDrive/Colab Notebooks/PusleDB/p043774.mat\"\n",
        "SEGMENT_LIMIT = None          # None = all segments\n",
        "PAD_LEN = 200\n",
        "SEC_PER_SEGMENT = 10.0\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SEED = 42\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "print(f\"Using Device: {DEVICE}\")\n",
        "\n",
        "# Phase-2 protocol config\n",
        "N_FOLDS = 5\n",
        "BLOCK_GAP_MIN = 0            # fixed: 0\n",
        "TIME_GAP_SWEEP_MIN = [0, 5, 10, 15]\n",
        "\n",
        "TRAIN_DUR_MIN = 10           # fixed\n",
        "TEST_DUR_MIN  = 5            # fixed\n",
        "VAL_FRAC_IN_TRAIN = 0.20     # last 20% of train indices\n",
        "\n",
        "# ==========================================\n",
        "# [1] Re-sample + Prior feature\n",
        "# ==========================================\n",
        "def cubic_resample(ppg, target_len=PAD_LEN):\n",
        "    \"\"\"Cubic spline interpolation (fallback to linear).\"\"\"\n",
        "    x_old = np.linspace(0, 1, len(ppg))\n",
        "    x_new = np.linspace(0, 1, target_len)\n",
        "    if len(ppg) < 4:\n",
        "        return np.interp(x_new, x_old, ppg).astype(np.float32)\n",
        "    try:\n",
        "        f = interp1d(x_old, ppg, kind=\"cubic\", bounds_error=False, fill_value=\"extrapolate\")\n",
        "        return f(x_new).astype(np.float32)\n",
        "    except Exception:\n",
        "        return np.interp(x_new, x_old, ppg).astype(np.float32)\n",
        "\n",
        "def extract_multiscale_morph_features(ppg_01):\n",
        "    \"\"\"\n",
        "    Multi-scale Morphological Feature Extraction (44 dims)\n",
        "    - PPG_F already 0~1 per segment => use directly\n",
        "    \"\"\"\n",
        "    scales = [100, 150, 200, 250]\n",
        "    all_features = []\n",
        "    for scale in scales:\n",
        "        x = cubic_resample(ppg_01, scale)\n",
        "\n",
        "        peak_idx = int(np.argmax(x))\n",
        "        end_idx = scale - 1\n",
        "\n",
        "        vp = float(x[peak_idx])\n",
        "        vt = float(x[end_idx])\n",
        "        dv = vp - vt\n",
        "        vm = float(np.mean(x))\n",
        "        std_val = float(np.std(x))\n",
        "\n",
        "        tvp = peak_idx / scale\n",
        "\n",
        "        diff = np.diff(x)\n",
        "        kmax = float(np.max(diff)) if len(diff) > 0 else 0.0\n",
        "        tkmax = (int(np.argmax(diff)) / scale) if len(diff) > 0 else 0.0\n",
        "\n",
        "        amax = float(trapezoid(x[:peak_idx])) if peak_idx > 0 else 0.0\n",
        "\n",
        "        centered = x - vm\n",
        "        skew_approx = float(np.mean(centered**3) / (std_val**3)) if std_val > 0 else 0.0\n",
        "        kurt_approx = float(np.mean(centered**4) / (std_val**4)) if std_val > 0 else 0.0\n",
        "\n",
        "        all_features.extend([vp, vt, dv, vm, kmax, tkmax, amax, std_val, tvp, skew_approx, kurt_approx])\n",
        "\n",
        "    return np.array(all_features, dtype=np.float32)\n",
        "\n",
        "# ==========================================\n",
        "# [2] Load data (PPG_F only)\n",
        "# ==========================================\n",
        "def load_data_from_mat(mat_path, segment_limit=None):\n",
        "    segments, priors, targets = [], [], []\n",
        "    with h5py.File(mat_path, \"r\") as f:\n",
        "        refs = f[\"Subj_Wins\"][\"PPG_F\"][0]\n",
        "        sbps = f[\"Subj_Wins\"][\"SegSBP\"][0]\n",
        "        dbps = f[\"Subj_Wins\"][\"SegDBP\"][0]\n",
        "\n",
        "        total = min(len(refs), segment_limit) if segment_limit else len(refs)\n",
        "        for i in range(total):\n",
        "            ppg = f[refs[i]][()].squeeze().astype(np.float32)   # (1250,) already 0~1\n",
        "            sbp = float(f[sbps[i]][()][0][0])\n",
        "            dbp = float(f[dbps[i]][()][0][0])\n",
        "\n",
        "            segments.append(ppg)\n",
        "            priors.append(extract_multiscale_morph_features(ppg))\n",
        "            targets.append([sbp, dbp])\n",
        "\n",
        "            if i % 1000 == 0:\n",
        "                print(f\"  Processed {i}/{total} ...\")\n",
        "\n",
        "    return segments, np.stack(priors).astype(np.float32), np.array(targets, dtype=np.float32)\n",
        "\n",
        "# ==========================================\n",
        "# [3] Dataset (RAW y; scaler is train-only)\n",
        "# ==========================================\n",
        "class PPGDatasetRawY(Dataset):\n",
        "    def __init__(self, segments, priors, targets_mmHg):\n",
        "        self.segments = segments            # list of (1250,)\n",
        "        self.priors = priors                # (N, 44)\n",
        "        self.targets = targets_mmHg         # (N, 2) in mmHg\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.segments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = cubic_resample(self.segments[idx], PAD_LEN)        # (200,)\n",
        "        x = torch.tensor(x, dtype=torch.float32).unsqueeze(0)  # (1, 200)\n",
        "        p = torch.tensor(self.priors[idx], dtype=torch.float32)\n",
        "        y = torch.tensor(self.targets[idx], dtype=torch.float32)  # RAW mmHg\n",
        "        return x, p, y\n",
        "\n",
        "# ==========================================\n",
        "# [4] Model\n",
        "# ==========================================\n",
        "class MorphCNNRegressor(nn.Module):\n",
        "    def __init__(self, prior_dim=44):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, 7, padding=3),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(32, 64, 5, padding=2),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(64, 128, 5, padding=2),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "\n",
        "        self.fc_prior = nn.Sequential(\n",
        "            nn.Linear(prior_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Sequential(\n",
        "            nn.Linear(256 + 256, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, prior):\n",
        "        feat = self.cnn(x).squeeze(-1)\n",
        "        pfeat = self.fc_prior(prior)\n",
        "        return self.fc_out(torch.cat([feat, pfeat], dim=1))\n",
        "\n",
        "# ==========================================\n",
        "# [5] Train-only label scaler\n",
        "# ==========================================\n",
        "class LabelScaler2D:\n",
        "    \"\"\"Train-only scaling. Default: minmax.\"\"\"\n",
        "    def __init__(self, mode=\"minmax\", eps=1e-6):\n",
        "        assert mode in [\"minmax\", \"zscore\"]\n",
        "        self.mode = mode\n",
        "        self.eps = eps\n",
        "        self.fitted = False\n",
        "\n",
        "    def fit(self, y_train_mmHg: np.ndarray):\n",
        "        y = np.asarray(y_train_mmHg, dtype=np.float32)\n",
        "        if self.mode == \"minmax\":\n",
        "            self.y_min = y.min(axis=0)\n",
        "            self.y_max = y.max(axis=0)\n",
        "        else:\n",
        "            self.y_mean = y.mean(axis=0)\n",
        "            self.y_std = y.std(axis=0)\n",
        "        self.fitted = True\n",
        "        return self\n",
        "\n",
        "    def transform(self, y_mmHg: torch.Tensor) -> torch.Tensor:\n",
        "        assert self.fitted\n",
        "        if self.mode == \"minmax\":\n",
        "            y_min = torch.tensor(self.y_min, device=y_mmHg.device, dtype=y_mmHg.dtype)\n",
        "            y_max = torch.tensor(self.y_max, device=y_mmHg.device, dtype=y_mmHg.dtype)\n",
        "            return (y_mmHg - y_min) / (y_max - y_min + self.eps)\n",
        "        else:\n",
        "            y_mean = torch.tensor(self.y_mean, device=y_mmHg.device, dtype=y_mmHg.dtype)\n",
        "            y_std = torch.tensor(self.y_std, device=y_mmHg.device, dtype=y_mmHg.dtype)\n",
        "            return (y_mmHg - y_mean) / (y_std + self.eps)\n",
        "\n",
        "    def inverse(self, y_scaled: torch.Tensor) -> torch.Tensor:\n",
        "        assert self.fitted\n",
        "        if self.mode == \"minmax\":\n",
        "            y_min = torch.tensor(self.y_min, device=y_scaled.device, dtype=y_scaled.dtype)\n",
        "            y_max = torch.tensor(self.y_max, device=y_scaled.device, dtype=y_scaled.dtype)\n",
        "            return y_scaled * (y_max - y_min + self.eps) + y_min\n",
        "        else:\n",
        "            y_mean = torch.tensor(self.y_mean, device=y_scaled.device, dtype=y_scaled.dtype)\n",
        "            y_std = torch.tensor(self.y_std, device=y_scaled.device, dtype=y_scaled.dtype)\n",
        "            return y_scaled * (y_std + self.eps) + y_mean\n",
        "\n",
        "# ==========================================\n",
        "# [6] Train / Eval\n",
        "# ==========================================\n",
        "def set_seed(seed=SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def train_one_model(train_loader, val_loader, scaler: LabelScaler2D):\n",
        "    model = MorphCNNRegressor(prior_dim=44).to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    best_val = float(\"inf\")\n",
        "    best_state = None\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        model.train()\n",
        "        for x, p, y_mmHg in train_loader:\n",
        "            x, p, y_mmHg = x.to(DEVICE), p.to(DEVICE), y_mmHg.to(DEVICE)\n",
        "            y = scaler.transform(y_mmHg)\n",
        "            pred = model(x, p)\n",
        "            loss = criterion(pred, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "        with torch.no_grad():\n",
        "            for x, p, y_mmHg in val_loader:\n",
        "                x, p, y_mmHg = x.to(DEVICE), p.to(DEVICE), y_mmHg.to(DEVICE)\n",
        "                y = scaler.transform(y_mmHg)\n",
        "                pred = model(x, p)\n",
        "                val_losses.append(float(criterion(pred, y).item()))\n",
        "        avg_val = float(np.mean(val_losses)) if len(val_losses) else float(\"inf\")\n",
        "\n",
        "        if avg_val < best_val:\n",
        "            best_val = avg_val\n",
        "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "    return model\n",
        "\n",
        "def eval_mae_sd_mmHg(model, loader, scaler: LabelScaler2D):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      - MAE (mean absolute error) for SBP/DBP\n",
        "      - SD  (std of signed error) for SBP/DBP\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    errs = []\n",
        "    with torch.no_grad():\n",
        "        for x, p, y_mmHg in loader:\n",
        "            x, p, y_mmHg = x.to(DEVICE), p.to(DEVICE), y_mmHg.to(DEVICE)\n",
        "            pred_scaled = model(x, p)\n",
        "            pred_mmHg = scaler.inverse(pred_scaled)\n",
        "            err = (pred_mmHg - y_mmHg).detach().cpu().numpy()  # signed\n",
        "            errs.append(err)\n",
        "\n",
        "    if len(errs) == 0:\n",
        "        return dict(mae_sbp=np.nan, sd_sbp=np.nan, mae_dbp=np.nan, sd_dbp=np.nan, n=0)\n",
        "\n",
        "    E = np.concatenate(errs, axis=0)  # (N,2)\n",
        "    e_sbp, e_dbp = E[:, 0], E[:, 1]\n",
        "    return dict(\n",
        "        mae_sbp=float(np.mean(np.abs(e_sbp))),\n",
        "        sd_sbp=float(np.std(e_sbp, ddof=0)),\n",
        "        mae_dbp=float(np.mean(np.abs(e_dbp))),\n",
        "        sd_dbp=float(np.std(e_dbp, ddof=0)),\n",
        "        n=int(E.shape[0])\n",
        "    )\n",
        "\n",
        "# ==========================================\n",
        "# [7] Phase-2 Engine (5-blocked time-wise CV, TimeGap sweep)\n",
        "# ==========================================\n",
        "def segs_from_minutes(minutes: float) -> int:\n",
        "    return int((minutes * 60.0) / SEC_PER_SEGMENT)\n",
        "\n",
        "def run_phase2_blocked_timewise_cv_timegap_sweep():\n",
        "    set_seed(SEED)\n",
        "\n",
        "    segments, priors, targets_mmHg = load_data_from_mat(MAT_FILE, segment_limit=SEGMENT_LIMIT)\n",
        "    ds = PPGDatasetRawY(segments, priors, targets_mmHg)\n",
        "\n",
        "    total_len = len(ds)\n",
        "    print(f\"\\n[Data Ready] total_len={total_len}\")\n",
        "\n",
        "    b_gap_segs = segs_from_minutes(BLOCK_GAP_MIN)\n",
        "    test_dur_segs  = segs_from_minutes(TEST_DUR_MIN)\n",
        "    train_dur_segs = segs_from_minutes(TRAIN_DUR_MIN)\n",
        "\n",
        "    # With BlockGap=0, fold_len is simply total_len // N_FOLDS (use contiguous blocks)\n",
        "    available_len = total_len - (N_FOLDS - 1) * b_gap_segs\n",
        "    if available_len <= 0:\n",
        "        raise ValueError(\"Not enough segments for the requested N_FOLDS and BLOCK_GAP_MIN.\")\n",
        "\n",
        "    fold_len = available_len // N_FOLDS\n",
        "    if fold_len <= 0:\n",
        "        raise ValueError(\"Computed fold_len <= 0. Reduce N_FOLDS or BLOCK_GAP_MIN.\")\n",
        "    if fold_len <= test_dur_segs + 1:\n",
        "        raise ValueError(\"Fold too short for test duration. Reduce TEST_DUR_MIN or N_FOLDS.\")\n",
        "\n",
        "    print(\"\\n=== PHASE 2 CONFIG ===\")\n",
        "    print(f\"N_FOLDS={N_FOLDS} | BlockGap={BLOCK_GAP_MIN}min ({b_gap_segs} segs)\")\n",
        "    print(f\"FoldLen={fold_len} segs (~{fold_len*SEC_PER_SEGMENT/60.0:.2f} min)\")\n",
        "    print(f\"TrainDur={TRAIN_DUR_MIN}min ({train_dur_segs} segs) | TestDur={TEST_DUR_MIN}min ({test_dur_segs} segs)\")\n",
        "    print(f\"TimeGap sweep (min): {TIME_GAP_SWEEP_MIN}\")\n",
        "    print(f\"ValFracInTrain={VAL_FRAC_IN_TRAIN:.2f}\")\n",
        "\n",
        "    t_global0 = time.time()\n",
        "\n",
        "    for gap_min in TIME_GAP_SWEEP_MIN:\n",
        "        gap_segs = segs_from_minutes(gap_min)\n",
        "        print(f\"\\n===============================\")\n",
        "        print(f\" TimeGap = {gap_min} min\")\n",
        "        print(f\"===============================\")\n",
        "\n",
        "        fold_stats = []\n",
        "        t_gap0 = time.time()\n",
        "\n",
        "        for f_idx in range(N_FOLDS):\n",
        "            fold_start = f_idx * (fold_len + b_gap_segs)\n",
        "            fold_end   = fold_start + fold_len\n",
        "\n",
        "            # test = last TEST_DUR_MIN minutes of the fold\n",
        "            test_end = fold_end\n",
        "            test_start = test_end - test_dur_segs\n",
        "\n",
        "            # train = TRAIN_DUR_MIN minutes ending at (test_start - gap)\n",
        "            train_end = test_start - gap_segs\n",
        "            train_start = train_end - train_dur_segs\n",
        "\n",
        "            # Feasibility: train must be inside the fold\n",
        "            if train_start < fold_start or train_end > test_start:\n",
        "                print(f\"[Fold {f_idx+1}] SKIP (insufficient room): \"\n",
        "                      f\"fold=({fold_start},{fold_end}) train=({train_start},{train_end}) test=({test_start},{test_end})\")\n",
        "                fold_stats.append(None)\n",
        "                continue\n",
        "\n",
        "            train_indices = list(range(train_start, train_end))\n",
        "            test_indices  = list(range(test_start, test_end))\n",
        "\n",
        "            # time-aware val split inside train (last 20%)\n",
        "            n_total = len(train_indices)\n",
        "            n_val = max(1, int(n_total * VAL_FRAC_IN_TRAIN))\n",
        "            if n_total - n_val < 1:\n",
        "                print(f\"[Fold {f_idx+1}] SKIP (train too small after val split).\")\n",
        "                fold_stats.append(None)\n",
        "                continue\n",
        "\n",
        "            real_train_idx = train_indices[:-n_val]\n",
        "            val_idx        = train_indices[-n_val:]\n",
        "\n",
        "            # TRAIN-only scaler fit (per fold)\n",
        "            y_train = targets_mmHg[np.array(real_train_idx)]\n",
        "            scaler = LabelScaler2D(mode=\"minmax\", eps=1e-6).fit(y_train)\n",
        "\n",
        "            train_loader = DataLoader(Subset(ds, real_train_idx), batch_size=BATCH_SIZE, shuffle=True)\n",
        "            val_loader   = DataLoader(Subset(ds, val_idx), batch_size=BATCH_SIZE, shuffle=False)\n",
        "            test_loader  = DataLoader(Subset(ds, test_indices), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "            t0 = time.time()\n",
        "            model = train_one_model(train_loader, val_loader, scaler)\n",
        "            stat = eval_mae_sd_mmHg(model, test_loader, scaler)\n",
        "            elapsed = time.time() - t0\n",
        "\n",
        "            stat.update({\n",
        "                \"fold\": f_idx + 1,\n",
        "                \"gap_min\": gap_min,\n",
        "                \"train_n\": len(real_train_idx),\n",
        "                \"val_n\": len(val_idx),\n",
        "                \"test_n\": len(test_indices),\n",
        "                \"elapsed_s\": float(elapsed),\n",
        "                \"fold_start\": fold_start,\n",
        "                \"fold_end\": fold_end,\n",
        "                \"train_start\": train_start,\n",
        "                \"train_end\": train_end,\n",
        "                \"test_start\": test_start,\n",
        "                \"test_end\": test_end,\n",
        "            })\n",
        "            fold_stats.append(stat)\n",
        "\n",
        "            print(f\"\\n[Fold {f_idx+1}] fold=({fold_start},{fold_end}) | \"\n",
        "                  f\"train=({train_start},{train_end}) | test=({test_start},{test_end})\")\n",
        "            print(f\"  sizes Train/Val/Test: {len(real_train_idx)}/{len(val_idx)}/{len(test_indices)}\")\n",
        "            print(f\"  SBP: MAE={stat['mae_sbp']:.4f} | SD={stat['sd_sbp']:.4f}\")\n",
        "            print(f\"  DBP: MAE={stat['mae_dbp']:.4f} | SD={stat['sd_dbp']:.4f}\")\n",
        "            print(f\"  elapsed: {elapsed:.1f}s\")\n",
        "\n",
        "        valid = [fs for fs in fold_stats if fs is not None and np.isfinite(fs[\"mae_sbp\"])]\n",
        "\n",
        "        def mean_key(key):\n",
        "            vals = [v[key] for v in valid]\n",
        "            return float(np.mean(vals)) if len(vals) else float(\"nan\")\n",
        "\n",
        "        print(f\"\\n--- TimeGap {gap_min} min SUMMARY ---\")\n",
        "        print(f\"ValidFolds: {len(valid)}/{N_FOLDS}\")\n",
        "        print(f\"Avg SBP: MAE={mean_key('mae_sbp'):.4f} | SD={mean_key('sd_sbp'):.4f}\")\n",
        "        print(f\"Avg DBP: MAE={mean_key('mae_dbp'):.4f} | SD={mean_key('sd_dbp'):.4f}\")\n",
        "        print(f\"Elapsed for this gap: {time.time() - t_gap0:.1f}s\")\n",
        "\n",
        "    print(f\"\\n[Phase2 Done] Total elapsed: {time.time() - t_global0:.1f}s\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_phase2_blocked_timewise_cv_timegap_sweep()\n"
      ]
    }
  ]
}