{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9yPWsejlDqy",
        "outputId": "45c352cf-654b-48fd-910a-15fa67f82e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cuda\n",
            "  Processed 0/1943 ...\n",
            "  Processed 1000/1943 ...\n",
            "\n",
            "[Data Ready] total_len=1943\n",
            "\n",
            "=== PHASE 3 CONFIG ===\n",
            "N_FOLDS=5 | BlockGap=0min (0 segs)\n",
            "FoldLen=388 segs (~64.67 min)\n",
            "TimeGap=5min (30 segs) | TestDur=5min (30 segs)\n",
            "TrainDur sweep (min): [3, 5, 10, 15]\n",
            "ValFracInTrain=0.20\n",
            "\n",
            "===============================\n",
            " TrainDur = 3 min\n",
            "===============================\n",
            "\n",
            "[Fold 1] fold=(0,388) | train=(310,328) | test=(358,388)\n",
            "  sizes Train/Val/Test: 15/3/30\n",
            "  SBP: MAE=1.5594 | SD=1.6445\n",
            "  DBP: MAE=0.7267 | SD=0.9312\n",
            "  elapsed: 8.7s\n",
            "\n",
            "[Fold 2] fold=(388,776) | train=(698,716) | test=(746,776)\n",
            "  sizes Train/Val/Test: 15/3/30\n",
            "  SBP: MAE=10.1082 | SD=1.4737\n",
            "  DBP: MAE=6.5883 | SD=0.9122\n",
            "  elapsed: 1.9s\n",
            "\n",
            "[Fold 3] fold=(776,1164) | train=(1086,1104) | test=(1134,1164)\n",
            "  sizes Train/Val/Test: 15/3/30\n",
            "  SBP: MAE=2.5289 | SD=2.3968\n",
            "  DBP: MAE=1.6592 | SD=1.3151\n",
            "  elapsed: 2.6s\n",
            "\n",
            "[Fold 4] fold=(1164,1552) | train=(1474,1492) | test=(1522,1552)\n",
            "  sizes Train/Val/Test: 15/3/30\n",
            "  SBP: MAE=6.7836 | SD=1.3052\n",
            "  DBP: MAE=3.4036 | SD=0.7297\n",
            "  elapsed: 2.5s\n",
            "\n",
            "[Fold 5] fold=(1552,1940) | train=(1862,1880) | test=(1910,1940)\n",
            "  sizes Train/Val/Test: 15/3/30\n",
            "  SBP: MAE=2.3591 | SD=3.0923\n",
            "  DBP: MAE=2.1485 | SD=1.6076\n",
            "  elapsed: 2.2s\n",
            "\n",
            "--- TrainDur 3 min SUMMARY (TimeGap=5min) ---\n",
            "ValidFolds: 5/5\n",
            "Avg SBP: MAE=4.6678 | SD=1.9825\n",
            "Avg DBP: MAE=2.9053 | SD=1.0992\n",
            "Elapsed for this TrainDur: 18.0s\n",
            "\n",
            "===============================\n",
            " TrainDur = 5 min\n",
            "===============================\n",
            "\n",
            "[Fold 1] fold=(0,388) | train=(298,328) | test=(358,388)\n",
            "  sizes Train/Val/Test: 24/6/30\n",
            "  SBP: MAE=1.7049 | SD=2.0326\n",
            "  DBP: MAE=0.8851 | SD=1.2448\n",
            "  elapsed: 3.4s\n",
            "\n",
            "[Fold 2] fold=(388,776) | train=(686,716) | test=(746,776)\n",
            "  sizes Train/Val/Test: 24/6/30\n",
            "  SBP: MAE=10.6732 | SD=1.5101\n",
            "  DBP: MAE=6.5561 | SD=0.9743\n",
            "  elapsed: 2.9s\n",
            "\n",
            "[Fold 3] fold=(776,1164) | train=(1074,1104) | test=(1134,1164)\n",
            "  sizes Train/Val/Test: 24/6/30\n",
            "  SBP: MAE=3.4040 | SD=2.7021\n",
            "  DBP: MAE=1.3194 | SD=1.8816\n",
            "  elapsed: 3.4s\n",
            "\n",
            "[Fold 4] fold=(1164,1552) | train=(1462,1492) | test=(1522,1552)\n",
            "  sizes Train/Val/Test: 24/6/30\n",
            "  SBP: MAE=4.8406 | SD=1.6066\n",
            "  DBP: MAE=2.5397 | SD=0.9209\n",
            "  elapsed: 2.8s\n",
            "\n",
            "[Fold 5] fold=(1552,1940) | train=(1850,1880) | test=(1910,1940)\n",
            "  sizes Train/Val/Test: 24/6/30\n",
            "  SBP: MAE=2.6842 | SD=2.6669\n",
            "  DBP: MAE=2.5113 | SD=1.4039\n",
            "  elapsed: 2.8s\n",
            "\n",
            "--- TrainDur 5 min SUMMARY (TimeGap=5min) ---\n",
            "ValidFolds: 5/5\n",
            "Avg SBP: MAE=4.6614 | SD=2.1037\n",
            "Avg DBP: MAE=2.7623 | SD=1.2851\n",
            "Elapsed for this TrainDur: 15.2s\n",
            "\n",
            "===============================\n",
            " TrainDur = 10 min\n",
            "===============================\n",
            "\n",
            "[Fold 1] fold=(0,388) | train=(268,328) | test=(358,388)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=2.4665 | SD=1.4857\n",
            "  DBP: MAE=0.7119 | SD=0.9375\n",
            "  elapsed: 5.5s\n",
            "\n",
            "[Fold 2] fold=(388,776) | train=(656,716) | test=(746,776)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=10.4500 | SD=1.6274\n",
            "  DBP: MAE=6.0765 | SD=1.0357\n",
            "  elapsed: 5.2s\n",
            "\n",
            "[Fold 3] fold=(776,1164) | train=(1044,1104) | test=(1134,1164)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=5.7389 | SD=2.4644\n",
            "  DBP: MAE=1.7421 | SD=1.5926\n",
            "  elapsed: 4.9s\n",
            "\n",
            "[Fold 4] fold=(1164,1552) | train=(1432,1492) | test=(1522,1552)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=4.7907 | SD=1.2336\n",
            "  DBP: MAE=1.7222 | SD=0.6400\n",
            "  elapsed: 5.8s\n",
            "\n",
            "[Fold 5] fold=(1552,1940) | train=(1820,1880) | test=(1910,1940)\n",
            "  sizes Train/Val/Test: 48/12/30\n",
            "  SBP: MAE=4.4186 | SD=3.6114\n",
            "  DBP: MAE=4.4584 | SD=1.7026\n",
            "  elapsed: 5.0s\n",
            "\n",
            "--- TrainDur 10 min SUMMARY (TimeGap=5min) ---\n",
            "ValidFolds: 5/5\n",
            "Avg SBP: MAE=5.5729 | SD=2.0845\n",
            "Avg DBP: MAE=2.9422 | SD=1.1817\n",
            "Elapsed for this TrainDur: 26.4s\n",
            "\n",
            "===============================\n",
            " TrainDur = 15 min\n",
            "===============================\n",
            "\n",
            "[Fold 1] fold=(0,388) | train=(238,328) | test=(358,388)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=1.5977 | SD=1.4937\n",
            "  DBP: MAE=1.1589 | SD=1.0039\n",
            "  elapsed: 8.3s\n",
            "\n",
            "[Fold 2] fold=(388,776) | train=(626,716) | test=(746,776)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=9.1309 | SD=1.4964\n",
            "  DBP: MAE=5.6748 | SD=0.9982\n",
            "  elapsed: 7.3s\n",
            "\n",
            "[Fold 3] fold=(776,1164) | train=(1014,1104) | test=(1134,1164)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=5.2708 | SD=3.0881\n",
            "  DBP: MAE=1.7016 | SD=1.5469\n",
            "  elapsed: 8.2s\n",
            "\n",
            "[Fold 4] fold=(1164,1552) | train=(1402,1492) | test=(1522,1552)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=6.0759 | SD=1.2821\n",
            "  DBP: MAE=3.0695 | SD=0.7529\n",
            "  elapsed: 7.7s\n",
            "\n",
            "[Fold 5] fold=(1552,1940) | train=(1790,1880) | test=(1910,1940)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=2.8456 | SD=2.9836\n",
            "  DBP: MAE=1.9504 | SD=1.3861\n",
            "  elapsed: 7.6s\n",
            "\n",
            "--- TrainDur 15 min SUMMARY (TimeGap=5min) ---\n",
            "ValidFolds: 5/5\n",
            "Avg SBP: MAE=4.9842 | SD=2.0688\n",
            "Avg DBP: MAE=2.7111 | SD=1.1376\n",
            "Elapsed for this TrainDur: 39.2s\n",
            "\n",
            "[Phase3 Done] Total elapsed: 98.7s\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Phase 3 â€” 5-blocked time-wise CV (p043774)\n",
        "#  - BlockGap = 0 (contiguous 5 folds)\n",
        "#  - TimeGap_min = 5 (FIXED; reviewer-friendly setting)\n",
        "#  - TestDur_min  = 5 (FIXED)\n",
        "#  - TrainDur sweep: [3, 5, 10, 15] (minutes)\n",
        "#  - Within each fold:\n",
        "#       Test  = last 5 minutes of the fold\n",
        "#       Train = TrainDur minutes ending at (test_start - time_gap)\n",
        "#       Val   = last 20% of TRAIN (time-aware, contiguous; no gap)\n",
        "#  - Input: PPG_F only (already per-segment min-max 0~1)\n",
        "#  - Label scaling: TRAIN-ONLY per fold (no future leakage)\n",
        "#  - Report:\n",
        "#       * per-fold MAE/SD for SBP/DBP\n",
        "#       * per-TrainDur average across valid folds\n",
        "#  - No CSV saving\n",
        "# ============================================================\n",
        "\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import h5py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.integrate import trapezoid\n",
        "\n",
        "# ==========================================\n",
        "# [0] Experiment settings\n",
        "# ==========================================\n",
        "MAT_FILE = \"/content/drive/MyDrive/Colab Notebooks/PusleDB/p043774.mat\"\n",
        "SEGMENT_LIMIT = None\n",
        "PAD_LEN = 200\n",
        "SEC_PER_SEGMENT = 10.0\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SEED = 42\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "print(f\"Using Device: {DEVICE}\")\n",
        "\n",
        "# Phase-3 protocol config\n",
        "N_FOLDS = 5\n",
        "BLOCK_GAP_MIN = 0                 # fixed\n",
        "TIME_GAP_MIN = 5                  # fixed (main protocol candidate)\n",
        "TEST_DUR_MIN = 5                  # fixed\n",
        "TRAIN_DUR_SWEEP_MIN = [3, 5, 10, 15]\n",
        "\n",
        "VAL_FRAC_IN_TRAIN = 0.20\n",
        "\n",
        "# ==========================================\n",
        "# [1] Re-sample + Prior feature\n",
        "# ==========================================\n",
        "def cubic_resample(ppg, target_len=PAD_LEN):\n",
        "    x_old = np.linspace(0, 1, len(ppg))\n",
        "    x_new = np.linspace(0, 1, target_len)\n",
        "    if len(ppg) < 4:\n",
        "        return np.interp(x_new, x_old, ppg).astype(np.float32)\n",
        "    try:\n",
        "        f = interp1d(x_old, ppg, kind=\"cubic\", bounds_error=False, fill_value=\"extrapolate\")\n",
        "        return f(x_new).astype(np.float32)\n",
        "    except Exception:\n",
        "        return np.interp(x_new, x_old, ppg).astype(np.float32)\n",
        "\n",
        "def extract_multiscale_morph_features(ppg_01):\n",
        "    scales = [100, 150, 200, 250]\n",
        "    all_features = []\n",
        "    for scale in scales:\n",
        "        x = cubic_resample(ppg_01, scale)\n",
        "\n",
        "        peak_idx = int(np.argmax(x))\n",
        "        end_idx = scale - 1\n",
        "\n",
        "        vp = float(x[peak_idx])\n",
        "        vt = float(x[end_idx])\n",
        "        dv = vp - vt\n",
        "        vm = float(np.mean(x))\n",
        "        std_val = float(np.std(x))\n",
        "\n",
        "        tvp = peak_idx / scale\n",
        "\n",
        "        diff = np.diff(x)\n",
        "        kmax = float(np.max(diff)) if len(diff) > 0 else 0.0\n",
        "        tkmax = (int(np.argmax(diff)) / scale) if len(diff) > 0 else 0.0\n",
        "\n",
        "        amax = float(trapezoid(x[:peak_idx])) if peak_idx > 0 else 0.0\n",
        "\n",
        "        centered = x - vm\n",
        "        skew_approx = float(np.mean(centered**3) / (std_val**3)) if std_val > 0 else 0.0\n",
        "        kurt_approx = float(np.mean(centered**4) / (std_val**4)) if std_val > 0 else 0.0\n",
        "\n",
        "        all_features.extend([vp, vt, dv, vm, kmax, tkmax, amax, std_val, tvp, skew_approx, kurt_approx])\n",
        "\n",
        "    return np.array(all_features, dtype=np.float32)\n",
        "\n",
        "# ==========================================\n",
        "# [2] Load data\n",
        "# ==========================================\n",
        "def load_data_from_mat(mat_path, segment_limit=None):\n",
        "    segments, priors, targets = [], [], []\n",
        "    with h5py.File(mat_path, \"r\") as f:\n",
        "        refs = f[\"Subj_Wins\"][\"PPG_F\"][0]\n",
        "        sbps = f[\"Subj_Wins\"][\"SegSBP\"][0]\n",
        "        dbps = f[\"Subj_Wins\"][\"SegDBP\"][0]\n",
        "\n",
        "        total = min(len(refs), segment_limit) if segment_limit else len(refs)\n",
        "        for i in range(total):\n",
        "            ppg = f[refs[i]][()].squeeze().astype(np.float32)\n",
        "            sbp = float(f[sbps[i]][()][0][0])\n",
        "            dbp = float(f[dbps[i]][()][0][0])\n",
        "\n",
        "            segments.append(ppg)\n",
        "            priors.append(extract_multiscale_morph_features(ppg))\n",
        "            targets.append([sbp, dbp])\n",
        "\n",
        "            if i % 1000 == 0:\n",
        "                print(f\"  Processed {i}/{total} ...\")\n",
        "\n",
        "    return segments, np.stack(priors).astype(np.float32), np.array(targets, dtype=np.float32)\n",
        "\n",
        "# ==========================================\n",
        "# [3] Dataset\n",
        "# ==========================================\n",
        "class PPGDatasetRawY(Dataset):\n",
        "    def __init__(self, segments, priors, targets_mmHg):\n",
        "        self.segments = segments\n",
        "        self.priors = priors\n",
        "        self.targets = targets_mmHg\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.segments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = cubic_resample(self.segments[idx], PAD_LEN)\n",
        "        x = torch.tensor(x, dtype=torch.float32).unsqueeze(0)\n",
        "        p = torch.tensor(self.priors[idx], dtype=torch.float32)\n",
        "        y = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
        "        return x, p, y\n",
        "\n",
        "# ==========================================\n",
        "# [4] Model\n",
        "# ==========================================\n",
        "class MorphCNNRegressor(nn.Module):\n",
        "    def __init__(self, prior_dim=44):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, 7, padding=3),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(32, 64, 5, padding=2),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(64, 128, 5, padding=2),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "\n",
        "        self.fc_prior = nn.Sequential(\n",
        "            nn.Linear(prior_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Sequential(\n",
        "            nn.Linear(256 + 256, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, prior):\n",
        "        feat = self.cnn(x).squeeze(-1)\n",
        "        pfeat = self.fc_prior(prior)\n",
        "        return self.fc_out(torch.cat([feat, pfeat], dim=1))\n",
        "\n",
        "# ==========================================\n",
        "# [5] Train-only label scaler\n",
        "# ==========================================\n",
        "class LabelScaler2D:\n",
        "    def __init__(self, mode=\"minmax\", eps=1e-6):\n",
        "        assert mode in [\"minmax\", \"zscore\"]\n",
        "        self.mode = mode\n",
        "        self.eps = eps\n",
        "        self.fitted = False\n",
        "\n",
        "    def fit(self, y_train_mmHg: np.ndarray):\n",
        "        y = np.asarray(y_train_mmHg, dtype=np.float32)\n",
        "        if self.mode == \"minmax\":\n",
        "            self.y_min = y.min(axis=0)\n",
        "            self.y_max = y.max(axis=0)\n",
        "        else:\n",
        "            self.y_mean = y.mean(axis=0)\n",
        "            self.y_std = y.std(axis=0)\n",
        "        self.fitted = True\n",
        "        return self\n",
        "\n",
        "    def transform(self, y_mmHg: torch.Tensor) -> torch.Tensor:\n",
        "        assert self.fitted\n",
        "        if self.mode == \"minmax\":\n",
        "            y_min = torch.tensor(self.y_min, device=y_mmHg.device, dtype=y_mmHg.dtype)\n",
        "            y_max = torch.tensor(self.y_max, device=y_mmHg.device, dtype=y_mmHg.dtype)\n",
        "            return (y_mmHg - y_min) / (y_max - y_min + self.eps)\n",
        "        else:\n",
        "            y_mean = torch.tensor(self.y_mean, device=y_mmHg.device, dtype=y_mmHg.dtype)\n",
        "            y_std = torch.tensor(self.y_std, device=y_mmHg.device, dtype=y_mmHg.dtype)\n",
        "            return (y_mmHg - y_mean) / (y_std + self.eps)\n",
        "\n",
        "    def inverse(self, y_scaled: torch.Tensor) -> torch.Tensor:\n",
        "        assert self.fitted\n",
        "        if self.mode == \"minmax\":\n",
        "            y_min = torch.tensor(self.y_min, device=y_scaled.device, dtype=y_scaled.dtype)\n",
        "            y_max = torch.tensor(self.y_max, device=y_scaled.device, dtype=y_scaled.dtype)\n",
        "            return y_scaled * (y_max - y_min + self.eps) + y_min\n",
        "        else:\n",
        "            y_mean = torch.tensor(self.y_mean, device=y_scaled.device, dtype=y_scaled.dtype)\n",
        "            y_std = torch.tensor(self.y_std, device=y_scaled.device, dtype=y_scaled.dtype)\n",
        "            return y_scaled * (y_std + self.eps) + y_mean\n",
        "\n",
        "# ==========================================\n",
        "# [6] Train / Eval\n",
        "# ==========================================\n",
        "def set_seed(seed=SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def train_one_model(train_loader, val_loader, scaler: LabelScaler2D):\n",
        "    model = MorphCNNRegressor(prior_dim=44).to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    best_val = float(\"inf\")\n",
        "    best_state = None\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        model.train()\n",
        "        for x, p, y_mmHg in train_loader:\n",
        "            x, p, y_mmHg = x.to(DEVICE), p.to(DEVICE), y_mmHg.to(DEVICE)\n",
        "            y = scaler.transform(y_mmHg)\n",
        "            pred = model(x, p)\n",
        "            loss = criterion(pred, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "        with torch.no_grad():\n",
        "            for x, p, y_mmHg in val_loader:\n",
        "                x, p, y_mmHg = x.to(DEVICE), p.to(DEVICE), y_mmHg.to(DEVICE)\n",
        "                y = scaler.transform(y_mmHg)\n",
        "                pred = model(x, p)\n",
        "                val_losses.append(float(criterion(pred, y).item()))\n",
        "        avg_val = float(np.mean(val_losses)) if len(val_losses) else float(\"inf\")\n",
        "\n",
        "        if avg_val < best_val:\n",
        "            best_val = avg_val\n",
        "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "    return model\n",
        "\n",
        "def eval_mae_sd_mmHg(model, loader, scaler: LabelScaler2D):\n",
        "    model.eval()\n",
        "    errs = []\n",
        "    with torch.no_grad():\n",
        "        for x, p, y_mmHg in loader:\n",
        "            x, p, y_mmHg = x.to(DEVICE), p.to(DEVICE), y_mmHg.to(DEVICE)\n",
        "            pred_scaled = model(x, p)\n",
        "            pred_mmHg = scaler.inverse(pred_scaled)\n",
        "            err = (pred_mmHg - y_mmHg).detach().cpu().numpy()\n",
        "            errs.append(err)\n",
        "\n",
        "    if len(errs) == 0:\n",
        "        return dict(mae_sbp=np.nan, sd_sbp=np.nan, mae_dbp=np.nan, sd_dbp=np.nan, n=0)\n",
        "\n",
        "    E = np.concatenate(errs, axis=0)\n",
        "    e_sbp, e_dbp = E[:, 0], E[:, 1]\n",
        "    return dict(\n",
        "        mae_sbp=float(np.mean(np.abs(e_sbp))),\n",
        "        sd_sbp=float(np.std(e_sbp, ddof=0)),\n",
        "        mae_dbp=float(np.mean(np.abs(e_dbp))),\n",
        "        sd_dbp=float(np.std(e_dbp, ddof=0)),\n",
        "        n=int(E.shape[0])\n",
        "    )\n",
        "\n",
        "# ==========================================\n",
        "# [7] Phase-3 Engine\n",
        "# ==========================================\n",
        "def segs_from_minutes(minutes: float) -> int:\n",
        "    return int((minutes * 60.0) / SEC_PER_SEGMENT)\n",
        "\n",
        "def run_phase3_blocked_timewise_cv_traindur_sweep():\n",
        "    set_seed(SEED)\n",
        "\n",
        "    segments, priors, targets_mmHg = load_data_from_mat(MAT_FILE, segment_limit=SEGMENT_LIMIT)\n",
        "    ds = PPGDatasetRawY(segments, priors, targets_mmHg)\n",
        "\n",
        "    total_len = len(ds)\n",
        "    print(f\"\\n[Data Ready] total_len={total_len}\")\n",
        "\n",
        "    b_gap_segs = segs_from_minutes(BLOCK_GAP_MIN)\n",
        "    gap_segs   = segs_from_minutes(TIME_GAP_MIN)\n",
        "    test_segs  = segs_from_minutes(TEST_DUR_MIN)\n",
        "\n",
        "    available_len = total_len - (N_FOLDS - 1) * b_gap_segs\n",
        "    if available_len <= 0:\n",
        "        raise ValueError(\"Not enough segments for the requested N_FOLDS and BLOCK_GAP_MIN.\")\n",
        "\n",
        "    fold_len = available_len // N_FOLDS\n",
        "    if fold_len <= 0:\n",
        "        raise ValueError(\"Computed fold_len <= 0.\")\n",
        "    if fold_len <= test_segs + 1:\n",
        "        raise ValueError(\"Fold too short for test duration.\")\n",
        "\n",
        "    print(\"\\n=== PHASE 3 CONFIG ===\")\n",
        "    print(f\"N_FOLDS={N_FOLDS} | BlockGap={BLOCK_GAP_MIN}min ({b_gap_segs} segs)\")\n",
        "    print(f\"FoldLen={fold_len} segs (~{fold_len*SEC_PER_SEGMENT/60.0:.2f} min)\")\n",
        "    print(f\"TimeGap={TIME_GAP_MIN}min ({gap_segs} segs) | TestDur={TEST_DUR_MIN}min ({test_segs} segs)\")\n",
        "    print(f\"TrainDur sweep (min): {TRAIN_DUR_SWEEP_MIN}\")\n",
        "    print(f\"ValFracInTrain={VAL_FRAC_IN_TRAIN:.2f}\")\n",
        "\n",
        "    t_global0 = time.time()\n",
        "\n",
        "    for tr_min in TRAIN_DUR_SWEEP_MIN:\n",
        "        tr_segs = segs_from_minutes(tr_min)\n",
        "\n",
        "        print(f\"\\n===============================\")\n",
        "        print(f\" TrainDur = {tr_min} min\")\n",
        "        print(f\"===============================\")\n",
        "\n",
        "        fold_stats = []\n",
        "        t_tr0 = time.time()\n",
        "\n",
        "        for f_idx in range(N_FOLDS):\n",
        "            fold_start = f_idx * (fold_len + b_gap_segs)\n",
        "            fold_end   = fold_start + fold_len\n",
        "\n",
        "            test_end = fold_end\n",
        "            test_start = test_end - test_segs\n",
        "\n",
        "            train_end = test_start - gap_segs\n",
        "            train_start = train_end - tr_segs\n",
        "\n",
        "            if train_start < fold_start or train_end > test_start:\n",
        "                print(f\"[Fold {f_idx+1}] SKIP (insufficient room): \"\n",
        "                      f\"fold=({fold_start},{fold_end}) train=({train_start},{train_end}) test=({test_start},{test_end})\")\n",
        "                fold_stats.append(None)\n",
        "                continue\n",
        "\n",
        "            train_indices = list(range(train_start, train_end))\n",
        "            test_indices  = list(range(test_start, test_end))\n",
        "\n",
        "            n_total = len(train_indices)\n",
        "            n_val = max(1, int(n_total * VAL_FRAC_IN_TRAIN))\n",
        "            if n_total - n_val < 1:\n",
        "                print(f\"[Fold {f_idx+1}] SKIP (train too small after val split).\")\n",
        "                fold_stats.append(None)\n",
        "                continue\n",
        "\n",
        "            real_train_idx = train_indices[:-n_val]\n",
        "            val_idx        = train_indices[-n_val:]\n",
        "\n",
        "            y_train = targets_mmHg[np.array(real_train_idx)]\n",
        "            scaler = LabelScaler2D(mode=\"minmax\", eps=1e-6).fit(y_train)\n",
        "\n",
        "            train_loader = DataLoader(Subset(ds, real_train_idx), batch_size=BATCH_SIZE, shuffle=True)\n",
        "            val_loader   = DataLoader(Subset(ds, val_idx), batch_size=BATCH_SIZE, shuffle=False)\n",
        "            test_loader  = DataLoader(Subset(ds, test_indices), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "            t0 = time.time()\n",
        "            model = train_one_model(train_loader, val_loader, scaler)\n",
        "            stat = eval_mae_sd_mmHg(model, test_loader, scaler)\n",
        "            elapsed = time.time() - t0\n",
        "\n",
        "            stat.update({\n",
        "                \"fold\": f_idx + 1,\n",
        "                \"train_dur_min\": tr_min,\n",
        "                \"train_n\": len(real_train_idx),\n",
        "                \"val_n\": len(val_idx),\n",
        "                \"test_n\": len(test_indices),\n",
        "                \"elapsed_s\": float(elapsed),\n",
        "            })\n",
        "            fold_stats.append(stat)\n",
        "\n",
        "            print(f\"\\n[Fold {f_idx+1}] fold=({fold_start},{fold_end}) | \"\n",
        "                  f\"train=({train_start},{train_end}) | test=({test_start},{test_end})\")\n",
        "            print(f\"  sizes Train/Val/Test: {len(real_train_idx)}/{len(val_idx)}/{len(test_indices)}\")\n",
        "            print(f\"  SBP: MAE={stat['mae_sbp']:.4f} | SD={stat['sd_sbp']:.4f}\")\n",
        "            print(f\"  DBP: MAE={stat['mae_dbp']:.4f} | SD={stat['sd_dbp']:.4f}\")\n",
        "            print(f\"  elapsed: {elapsed:.1f}s\")\n",
        "\n",
        "        valid = [fs for fs in fold_stats if fs is not None and np.isfinite(fs[\"mae_sbp\"])]\n",
        "\n",
        "        def mean_key(key):\n",
        "            vals = [v[key] for v in valid]\n",
        "            return float(np.mean(vals)) if len(vals) else float(\"nan\")\n",
        "\n",
        "        print(f\"\\n--- TrainDur {tr_min} min SUMMARY (TimeGap={TIME_GAP_MIN}min) ---\")\n",
        "        print(f\"ValidFolds: {len(valid)}/{N_FOLDS}\")\n",
        "        print(f\"Avg SBP: MAE={mean_key('mae_sbp'):.4f} | SD={mean_key('sd_sbp'):.4f}\")\n",
        "        print(f\"Avg DBP: MAE={mean_key('mae_dbp'):.4f} | SD={mean_key('sd_dbp'):.4f}\")\n",
        "        print(f\"Elapsed for this TrainDur: {time.time() - t_tr0:.1f}s\")\n",
        "\n",
        "    print(f\"\\n[Phase3 Done] Total elapsed: {time.time() - t_global0:.1f}s\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_phase3_blocked_timewise_cv_traindur_sweep()\n"
      ]
    }
  ]
}