{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8PxsRw9nrK5",
        "outputId": "e00d3b8b-1d66-4078-f078-1787b0ce0f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cuda\n",
            "  Processed 0/1943 ...\n",
            "  Processed 1000/1943 ...\n",
            "\n",
            "[Data Ready] total_len=1943\n",
            "\n",
            "=== PHASE 4 CONFIG ===\n",
            "N_FOLDS=5\n",
            "TimeGap=5min (30 segs) | TrainDur=15min (90 segs) | TestDur=5min (30 segs)\n",
            "BlockGap sweep (min): [0, 3, 5, 10]\n",
            "ValFracInTrain=0.20\n",
            "\n",
            "===============================\n",
            " BlockGap = 0 min\n",
            "===============================\n",
            "BlockGap=0min (0 segs) | FoldLen=388 segs (~64.67 min)\n",
            "\n",
            "[Fold 1] fold=(0,388) | train=(238,328) | test=(358,388)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=1.6373 | SD=1.3991\n",
            "  DBP: MAE=1.2606 | SD=1.1188\n",
            "  elapsed: 10.1s\n",
            "\n",
            "[Fold 2] fold=(388,776) | train=(626,716) | test=(746,776)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=9.0255 | SD=1.7981\n",
            "  DBP: MAE=5.7918 | SD=1.0756\n",
            "  elapsed: 7.0s\n",
            "\n",
            "[Fold 3] fold=(776,1164) | train=(1014,1104) | test=(1134,1164)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=6.0147 | SD=2.8333\n",
            "  DBP: MAE=2.1660 | SD=1.8980\n",
            "  elapsed: 8.7s\n",
            "\n",
            "[Fold 4] fold=(1164,1552) | train=(1402,1492) | test=(1522,1552)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=5.3061 | SD=1.8340\n",
            "  DBP: MAE=3.1984 | SD=0.7567\n",
            "  elapsed: 7.3s\n",
            "\n",
            "[Fold 5] fold=(1552,1940) | train=(1790,1880) | test=(1910,1940)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=2.5025 | SD=2.9750\n",
            "  DBP: MAE=1.8438 | SD=1.3888\n",
            "  elapsed: 8.2s\n",
            "\n",
            "--- BlockGap 0 min SUMMARY ---\n",
            "ValidFolds: 5/5\n",
            "Avg   SBP: MAE=4.8972 | SD=2.1679\n",
            "Avg   DBP: MAE=2.8521 | SD=1.2476\n",
            "Worst SBP: MAE=9.0255 |  StdAcrossFolds(MAE)=2.6390\n",
            "Worst DBP: MAE=5.7918 |  StdAcrossFolds(MAE)=1.5989\n",
            "Elapsed for this BlockGap: 41.3s\n",
            "\n",
            "===============================\n",
            " BlockGap = 3 min\n",
            "===============================\n",
            "BlockGap=3min (18 segs) | FoldLen=374 segs (~62.33 min)\n",
            "\n",
            "[Fold 1] fold=(0,374) | train=(224,314) | test=(344,374)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=1.6650 | SD=1.5432\n",
            "  DBP: MAE=1.5607 | SD=1.3493\n",
            "  elapsed: 8.1s\n",
            "\n",
            "[Fold 2] fold=(392,766) | train=(616,706) | test=(736,766)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=2.9384 | SD=2.1304\n",
            "  DBP: MAE=1.6734 | SD=1.3467\n",
            "  elapsed: 7.3s\n",
            "\n",
            "[Fold 3] fold=(784,1158) | train=(1008,1098) | test=(1128,1158)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=7.2925 | SD=2.5666\n",
            "  DBP: MAE=3.1254 | SD=1.4236\n",
            "  elapsed: 8.2s\n",
            "\n",
            "[Fold 4] fold=(1176,1550) | train=(1400,1490) | test=(1520,1550)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=6.4289 | SD=1.5255\n",
            "  DBP: MAE=2.9617 | SD=0.9680\n",
            "  elapsed: 7.3s\n",
            "\n",
            "[Fold 5] fold=(1568,1942) | train=(1792,1882) | test=(1912,1942)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=2.4505 | SD=3.1687\n",
            "  DBP: MAE=1.6345 | SD=1.3208\n",
            "  elapsed: 8.7s\n",
            "\n",
            "--- BlockGap 3 min SUMMARY ---\n",
            "ValidFolds: 5/5\n",
            "Avg   SBP: MAE=4.1551 | SD=2.1869\n",
            "Avg   DBP: MAE=2.1911 | SD=1.2817\n",
            "Worst SBP: MAE=7.2925 |  StdAcrossFolds(MAE)=2.2627\n",
            "Worst DBP: MAE=3.1254 |  StdAcrossFolds(MAE)=0.6988\n",
            "Elapsed for this BlockGap: 39.5s\n",
            "\n",
            "===============================\n",
            " BlockGap = 5 min\n",
            "===============================\n",
            "BlockGap=5min (30 segs) | FoldLen=364 segs (~60.67 min)\n",
            "\n",
            "[Fold 1] fold=(0,364) | train=(214,304) | test=(334,364)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=3.1445 | SD=2.0517\n",
            "  DBP: MAE=0.9876 | SD=1.1604\n",
            "  elapsed: 8.3s\n",
            "\n",
            "[Fold 2] fold=(394,758) | train=(608,698) | test=(728,758)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=6.4525 | SD=2.3417\n",
            "  DBP: MAE=3.6011 | SD=1.4596\n",
            "  elapsed: 8.7s\n",
            "\n",
            "[Fold 3] fold=(788,1152) | train=(1002,1092) | test=(1122,1152)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=8.8020 | SD=2.1133\n",
            "  DBP: MAE=3.7344 | SD=1.0470\n",
            "  elapsed: 8.6s\n",
            "\n",
            "[Fold 4] fold=(1182,1546) | train=(1396,1486) | test=(1516,1546)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=6.2102 | SD=1.6570\n",
            "  DBP: MAE=2.6713 | SD=0.8989\n",
            "  elapsed: 7.7s\n",
            "\n",
            "[Fold 5] fold=(1576,1940) | train=(1790,1880) | test=(1910,1940)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=2.2199 | SD=2.5281\n",
            "  DBP: MAE=2.6711 | SD=1.2784\n",
            "  elapsed: 8.3s\n",
            "\n",
            "--- BlockGap 5 min SUMMARY ---\n",
            "ValidFolds: 5/5\n",
            "Avg   SBP: MAE=5.3658 | SD=2.1384\n",
            "Avg   DBP: MAE=2.7331 | SD=1.1689\n",
            "Worst SBP: MAE=8.8020 |  StdAcrossFolds(MAE)=2.3888\n",
            "Worst DBP: MAE=3.7344 |  StdAcrossFolds(MAE)=0.9808\n",
            "Elapsed for this BlockGap: 41.5s\n",
            "\n",
            "===============================\n",
            " BlockGap = 10 min\n",
            "===============================\n",
            "BlockGap=10min (60 segs) | FoldLen=340 segs (~56.67 min)\n",
            "\n",
            "[Fold 1] fold=(0,340) | train=(190,280) | test=(310,340)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=1.5822 | SD=1.9589\n",
            "  DBP: MAE=1.2967 | SD=1.4420\n",
            "  elapsed: 8.5s\n",
            "\n",
            "[Fold 2] fold=(400,740) | train=(590,680) | test=(710,740)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=14.2144 | SD=7.9415\n",
            "  DBP: MAE=8.2237 | SD=4.7391\n",
            "  elapsed: 7.4s\n",
            "\n",
            "[Fold 3] fold=(800,1140) | train=(990,1080) | test=(1110,1140)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=10.9815 | SD=3.0872\n",
            "  DBP: MAE=4.4211 | SD=1.0805\n",
            "  elapsed: 8.6s\n",
            "\n",
            "[Fold 4] fold=(1200,1540) | train=(1390,1480) | test=(1510,1540)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=5.7536 | SD=1.6519\n",
            "  DBP: MAE=2.4203 | SD=1.0343\n",
            "  elapsed: 7.8s\n",
            "\n",
            "[Fold 5] fold=(1600,1940) | train=(1790,1880) | test=(1910,1940)\n",
            "  sizes Train/Val/Test: 72/18/30\n",
            "  SBP: MAE=2.8179 | SD=2.6958\n",
            "  DBP: MAE=1.9008 | SD=1.3164\n",
            "  elapsed: 8.0s\n",
            "\n",
            "--- BlockGap 10 min SUMMARY ---\n",
            "ValidFolds: 5/5\n",
            "Avg   SBP: MAE=7.0699 | SD=3.4671\n",
            "Avg   DBP: MAE=3.6525 | SD=1.9225\n",
            "Worst SBP: MAE=14.2144 |  StdAcrossFolds(MAE)=4.8222\n",
            "Worst DBP: MAE=8.2237 |  StdAcrossFolds(MAE)=2.5149\n",
            "Elapsed for this BlockGap: 40.3s\n",
            "\n",
            "[Phase4 Done] Total elapsed: 162.8s\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Phase 4 â€” 5-blocked time-wise CV (p043774)\n",
        "#  - TimeGap_min = 5 (FIXED; reviewer-friendly)\n",
        "#  - TrainDur_min = 5 (FIXED; stable pass candidate)\n",
        "#  - TestDur_min  = 5 (FIXED)\n",
        "#  - BlockGap sweep: [0, 3, 5, 10] (minutes)\n",
        "#  - Within each fold:\n",
        "#       Test  = last 5 minutes of the fold\n",
        "#       Train = 5 minutes ending at (test_start - time_gap)\n",
        "#       Val   = last 20% of TRAIN (time-aware, contiguous; no gap)\n",
        "#  - Input: PPG_F only (already per-segment min-max 0~1)\n",
        "#  - Label scaling: TRAIN-ONLY per fold (no future leakage)\n",
        "#  - Report:\n",
        "#       * per-fold MAE/SD for SBP/DBP\n",
        "#       * per-BlockGap summary:\n",
        "#            - Avg MAE/SD\n",
        "#            - WorstFold MAE (SBP/DBP)\n",
        "#            - StdAcrossFolds of MAE (SBP/DBP)\n",
        "#  - No CSV saving\n",
        "# ============================================================\n",
        "\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import h5py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.integrate import trapezoid\n",
        "\n",
        "# ==========================================\n",
        "# [0] Experiment settings\n",
        "# ==========================================\n",
        "MAT_FILE = \"/content/drive/MyDrive/Colab Notebooks/PusleDB/p043774.mat\"\n",
        "SEGMENT_LIMIT = None\n",
        "PAD_LEN = 200\n",
        "SEC_PER_SEGMENT = 10.0\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SEED = 42\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "print(f\"Using Device: {DEVICE}\")\n",
        "\n",
        "# Phase-4 protocol config\n",
        "N_FOLDS = 5\n",
        "TIME_GAP_MIN = 5\n",
        "TRAIN_DUR_MIN = 15\n",
        "TEST_DUR_MIN = 5\n",
        "BLOCK_GAP_SWEEP_MIN = [0, 3, 5, 10]\n",
        "\n",
        "VAL_FRAC_IN_TRAIN = 0.20\n",
        "\n",
        "# ==========================================\n",
        "# [1] Re-sample + Prior feature\n",
        "# ==========================================\n",
        "def cubic_resample(ppg, target_len=PAD_LEN):\n",
        "    x_old = np.linspace(0, 1, len(ppg))\n",
        "    x_new = np.linspace(0, 1, target_len)\n",
        "    if len(ppg) < 4:\n",
        "        return np.interp(x_new, x_old, ppg).astype(np.float32)\n",
        "    try:\n",
        "        f = interp1d(x_old, ppg, kind=\"cubic\", bounds_error=False, fill_value=\"extrapolate\")\n",
        "        return f(x_new).astype(np.float32)\n",
        "    except Exception:\n",
        "        return np.interp(x_new, x_old, ppg).astype(np.float32)\n",
        "\n",
        "def extract_multiscale_morph_features(ppg_01):\n",
        "    scales = [100, 150, 200, 250]\n",
        "    all_features = []\n",
        "    for scale in scales:\n",
        "        x = cubic_resample(ppg_01, scale)\n",
        "\n",
        "        peak_idx = int(np.argmax(x))\n",
        "        end_idx = scale - 1\n",
        "\n",
        "        vp = float(x[peak_idx])\n",
        "        vt = float(x[end_idx])\n",
        "        dv = vp - vt\n",
        "        vm = float(np.mean(x))\n",
        "        std_val = float(np.std(x))\n",
        "\n",
        "        tvp = peak_idx / scale\n",
        "\n",
        "        diff = np.diff(x)\n",
        "        kmax = float(np.max(diff)) if len(diff) > 0 else 0.0\n",
        "        tkmax = (int(np.argmax(diff)) / scale) if len(diff) > 0 else 0.0\n",
        "\n",
        "        amax = float(trapezoid(x[:peak_idx])) if peak_idx > 0 else 0.0\n",
        "\n",
        "        centered = x - vm\n",
        "        skew_approx = float(np.mean(centered**3) / (std_val**3)) if std_val > 0 else 0.0\n",
        "        kurt_approx = float(np.mean(centered**4) / (std_val**4)) if std_val > 0 else 0.0\n",
        "\n",
        "        all_features.extend([vp, vt, dv, vm, kmax, tkmax, amax, std_val, tvp, skew_approx, kurt_approx])\n",
        "\n",
        "    return np.array(all_features, dtype=np.float32)\n",
        "\n",
        "# ==========================================\n",
        "# [2] Load data\n",
        "# ==========================================\n",
        "def load_data_from_mat(mat_path, segment_limit=None):\n",
        "    segments, priors, targets = [], [], []\n",
        "    with h5py.File(mat_path, \"r\") as f:\n",
        "        refs = f[\"Subj_Wins\"][\"PPG_F\"][0]\n",
        "        sbps = f[\"Subj_Wins\"][\"SegSBP\"][0]\n",
        "        dbps = f[\"Subj_Wins\"][\"SegDBP\"][0]\n",
        "\n",
        "        total = min(len(refs), segment_limit) if segment_limit else len(refs)\n",
        "        for i in range(total):\n",
        "            ppg = f[refs[i]][()].squeeze().astype(np.float32)\n",
        "            sbp = float(f[sbps[i]][()][0][0])\n",
        "            dbp = float(f[dbps[i]][()][0][0])\n",
        "\n",
        "            segments.append(ppg)\n",
        "            priors.append(extract_multiscale_morph_features(ppg))\n",
        "            targets.append([sbp, dbp])\n",
        "\n",
        "            if i % 1000 == 0:\n",
        "                print(f\"  Processed {i}/{total} ...\")\n",
        "\n",
        "    return segments, np.stack(priors).astype(np.float32), np.array(targets, dtype=np.float32)\n",
        "\n",
        "# ==========================================\n",
        "# [3] Dataset\n",
        "# ==========================================\n",
        "class PPGDatasetRawY(Dataset):\n",
        "    def __init__(self, segments, priors, targets_mmHg):\n",
        "        self.segments = segments\n",
        "        self.priors = priors\n",
        "        self.targets = targets_mmHg\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.segments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = cubic_resample(self.segments[idx], PAD_LEN)\n",
        "        x = torch.tensor(x, dtype=torch.float32).unsqueeze(0)\n",
        "        p = torch.tensor(self.priors[idx], dtype=torch.float32)\n",
        "        y = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
        "        return x, p, y\n",
        "\n",
        "# ==========================================\n",
        "# [4] Model\n",
        "# ==========================================\n",
        "class MorphCNNRegressor(nn.Module):\n",
        "    def __init__(self, prior_dim=44):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, 7, padding=3),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(32, 64, 5, padding=2),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(64, 128, 5, padding=2),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "\n",
        "        self.fc_prior = nn.Sequential(\n",
        "            nn.Linear(prior_dim, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Sequential(\n",
        "            nn.Linear(256 + 256, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, prior):\n",
        "        feat = self.cnn(x).squeeze(-1)\n",
        "        pfeat = self.fc_prior(prior)\n",
        "        return self.fc_out(torch.cat([feat, pfeat], dim=1))\n",
        "\n",
        "# ==========================================\n",
        "# [5] Train-only label scaler\n",
        "# ==========================================\n",
        "class LabelScaler2D:\n",
        "    def __init__(self, mode=\"minmax\", eps=1e-6):\n",
        "        assert mode in [\"minmax\", \"zscore\"]\n",
        "        self.mode = mode\n",
        "        self.eps = eps\n",
        "        self.fitted = False\n",
        "\n",
        "    def fit(self, y_train_mmHg: np.ndarray):\n",
        "        y = np.asarray(y_train_mmHg, dtype=np.float32)\n",
        "        if self.mode == \"minmax\":\n",
        "            self.y_min = y.min(axis=0)\n",
        "            self.y_max = y.max(axis=0)\n",
        "        else:\n",
        "            self.y_mean = y.mean(axis=0)\n",
        "            self.y_std = y.std(axis=0)\n",
        "        self.fitted = True\n",
        "        return self\n",
        "\n",
        "    def transform(self, y_mmHg: torch.Tensor) -> torch.Tensor:\n",
        "        assert self.fitted\n",
        "        if self.mode == \"minmax\":\n",
        "            y_min = torch.tensor(self.y_min, device=y_mmHg.device, dtype=y_mmHg.dtype)\n",
        "            y_max = torch.tensor(self.y_max, device=y_mmHg.device, dtype=y_mmHg.dtype)\n",
        "            return (y_mmHg - y_min) / (y_max - y_min + self.eps)\n",
        "        else:\n",
        "            y_mean = torch.tensor(self.y_mean, device=y_mmHg.device, dtype=y_mmHg.dtype)\n",
        "            y_std = torch.tensor(self.y_std, device=y_mmHg.device, dtype=y_mmHg.dtype)\n",
        "            return (y_mmHg - y_mean) / (y_std + self.eps)\n",
        "\n",
        "    def inverse(self, y_scaled: torch.Tensor) -> torch.Tensor:\n",
        "        assert self.fitted\n",
        "        if self.mode == \"minmax\":\n",
        "            y_min = torch.tensor(self.y_min, device=y_scaled.device, dtype=y_scaled.dtype)\n",
        "            y_max = torch.tensor(self.y_max, device=y_scaled.device, dtype=y_scaled.dtype)\n",
        "            return y_scaled * (y_max - y_min + self.eps) + y_min\n",
        "        else:\n",
        "            y_mean = torch.tensor(self.y_mean, device=y_scaled.device, dtype=y_scaled.dtype)\n",
        "            y_std = torch.tensor(self.y_std, device=y_scaled.device, dtype=y_scaled.dtype)\n",
        "            return y_scaled * (y_std + self.eps) + y_mean\n",
        "\n",
        "# ==========================================\n",
        "# [6] Train / Eval\n",
        "# ==========================================\n",
        "def set_seed(seed=SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def train_one_model(train_loader, val_loader, scaler: LabelScaler2D):\n",
        "    model = MorphCNNRegressor(prior_dim=44).to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    best_val = float(\"inf\")\n",
        "    best_state = None\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        model.train()\n",
        "        for x, p, y_mmHg in train_loader:\n",
        "            x, p, y_mmHg = x.to(DEVICE), p.to(DEVICE), y_mmHg.to(DEVICE)\n",
        "            y = scaler.transform(y_mmHg)\n",
        "            pred = model(x, p)\n",
        "            loss = criterion(pred, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "        with torch.no_grad():\n",
        "            for x, p, y_mmHg in val_loader:\n",
        "                x, p, y_mmHg = x.to(DEVICE), p.to(DEVICE), y_mmHg.to(DEVICE)\n",
        "                y = scaler.transform(y_mmHg)\n",
        "                pred = model(x, p)\n",
        "                val_losses.append(float(criterion(pred, y).item()))\n",
        "        avg_val = float(np.mean(val_losses)) if len(val_losses) else float(\"inf\")\n",
        "\n",
        "        if avg_val < best_val:\n",
        "            best_val = avg_val\n",
        "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "    return model\n",
        "\n",
        "def eval_mae_sd_mmHg(model, loader, scaler: LabelScaler2D):\n",
        "    model.eval()\n",
        "    errs = []\n",
        "    with torch.no_grad():\n",
        "        for x, p, y_mmHg in loader:\n",
        "            x, p, y_mmHg = x.to(DEVICE), p.to(DEVICE), y_mmHg.to(DEVICE)\n",
        "            pred_scaled = model(x, p)\n",
        "            pred_mmHg = scaler.inverse(pred_scaled)\n",
        "            err = (pred_mmHg - y_mmHg).detach().cpu().numpy()\n",
        "            errs.append(err)\n",
        "\n",
        "    if len(errs) == 0:\n",
        "        return dict(mae_sbp=np.nan, sd_sbp=np.nan, mae_dbp=np.nan, sd_dbp=np.nan, n=0)\n",
        "\n",
        "    E = np.concatenate(errs, axis=0)\n",
        "    e_sbp, e_dbp = E[:, 0], E[:, 1]\n",
        "    return dict(\n",
        "        mae_sbp=float(np.mean(np.abs(e_sbp))),\n",
        "        sd_sbp=float(np.std(e_sbp, ddof=0)),\n",
        "        mae_dbp=float(np.mean(np.abs(e_dbp))),\n",
        "        sd_dbp=float(np.std(e_dbp, ddof=0)),\n",
        "        n=int(E.shape[0])\n",
        "    )\n",
        "\n",
        "# ==========================================\n",
        "# [7] Phase-4 Engine (BlockGap sweep)\n",
        "# ==========================================\n",
        "def segs_from_minutes(minutes: float) -> int:\n",
        "    return int((minutes * 60.0) / SEC_PER_SEGMENT)\n",
        "\n",
        "def summarize_folds(valid_stats):\n",
        "    mae_sbp = np.array([v[\"mae_sbp\"] for v in valid_stats], dtype=np.float32)\n",
        "    mae_dbp = np.array([v[\"mae_dbp\"] for v in valid_stats], dtype=np.float32)\n",
        "    sd_sbp  = np.array([v[\"sd_sbp\"]  for v in valid_stats], dtype=np.float32)\n",
        "    sd_dbp  = np.array([v[\"sd_dbp\"]  for v in valid_stats], dtype=np.float32)\n",
        "\n",
        "    return {\n",
        "        \"avg_mae_sbp\": float(mae_sbp.mean()) if len(mae_sbp) else float(\"nan\"),\n",
        "        \"avg_mae_dbp\": float(mae_dbp.mean()) if len(mae_dbp) else float(\"nan\"),\n",
        "        \"avg_sd_sbp\":  float(sd_sbp.mean())  if len(sd_sbp)  else float(\"nan\"),\n",
        "        \"avg_sd_dbp\":  float(sd_dbp.mean())  if len(sd_dbp)  else float(\"nan\"),\n",
        "        \"worst_mae_sbp\": float(mae_sbp.max()) if len(mae_sbp) else float(\"nan\"),\n",
        "        \"worst_mae_dbp\": float(mae_dbp.max()) if len(mae_dbp) else float(\"nan\"),\n",
        "        \"std_mae_sbp\": float(mae_sbp.std(ddof=0)) if len(mae_sbp) else float(\"nan\"),\n",
        "        \"std_mae_dbp\": float(mae_dbp.std(ddof=0)) if len(mae_dbp) else float(\"nan\"),\n",
        "    }\n",
        "\n",
        "def run_phase4_blockgap_sweep():\n",
        "    set_seed(SEED)\n",
        "\n",
        "    segments, priors, targets_mmHg = load_data_from_mat(MAT_FILE, segment_limit=SEGMENT_LIMIT)\n",
        "    ds = PPGDatasetRawY(segments, priors, targets_mmHg)\n",
        "\n",
        "    total_len = len(ds)\n",
        "    print(f\"\\n[Data Ready] total_len={total_len}\")\n",
        "\n",
        "    gap_segs  = segs_from_minutes(TIME_GAP_MIN)\n",
        "    test_segs = segs_from_minutes(TEST_DUR_MIN)\n",
        "    tr_segs   = segs_from_minutes(TRAIN_DUR_MIN)\n",
        "\n",
        "    print(\"\\n=== PHASE 4 CONFIG ===\")\n",
        "    print(f\"N_FOLDS={N_FOLDS}\")\n",
        "    print(f\"TimeGap={TIME_GAP_MIN}min ({gap_segs} segs) | TrainDur={TRAIN_DUR_MIN}min ({tr_segs} segs) | TestDur={TEST_DUR_MIN}min ({test_segs} segs)\")\n",
        "    print(f\"BlockGap sweep (min): {BLOCK_GAP_SWEEP_MIN}\")\n",
        "    print(f\"ValFracInTrain={VAL_FRAC_IN_TRAIN:.2f}\")\n",
        "\n",
        "    t_global0 = time.time()\n",
        "\n",
        "    for bg_min in BLOCK_GAP_SWEEP_MIN:\n",
        "        b_gap_segs = segs_from_minutes(bg_min)\n",
        "\n",
        "        available_len = total_len - (N_FOLDS - 1) * b_gap_segs\n",
        "        if available_len <= 0:\n",
        "            print(f\"\\n[BlockGap {bg_min}m] SKIP (available_len<=0).\")\n",
        "            continue\n",
        "\n",
        "        fold_len = available_len // N_FOLDS\n",
        "        if fold_len <= 0 or fold_len <= test_segs + 1:\n",
        "            print(f\"\\n[BlockGap {bg_min}m] SKIP (fold_len too small). fold_len={fold_len}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n===============================\")\n",
        "        print(f\" BlockGap = {bg_min} min\")\n",
        "        print(f\"===============================\")\n",
        "        print(f\"BlockGap={bg_min}min ({b_gap_segs} segs) | FoldLen={fold_len} segs (~{fold_len*SEC_PER_SEGMENT/60.0:.2f} min)\")\n",
        "\n",
        "        fold_stats = []\n",
        "        t_bg0 = time.time()\n",
        "\n",
        "        for f_idx in range(N_FOLDS):\n",
        "            fold_start = f_idx * (fold_len + b_gap_segs)\n",
        "            fold_end   = fold_start + fold_len\n",
        "\n",
        "            test_end = fold_end\n",
        "            test_start = test_end - test_segs\n",
        "\n",
        "            train_end = test_start - gap_segs\n",
        "            train_start = train_end - tr_segs\n",
        "\n",
        "            if train_start < fold_start or train_end > test_start:\n",
        "                print(f\"[Fold {f_idx+1}] SKIP (insufficient room): \"\n",
        "                      f\"fold=({fold_start},{fold_end}) train=({train_start},{train_end}) test=({test_start},{test_end})\")\n",
        "                fold_stats.append(None)\n",
        "                continue\n",
        "\n",
        "            train_indices = list(range(train_start, train_end))\n",
        "            test_indices  = list(range(test_start, test_end))\n",
        "\n",
        "            n_total = len(train_indices)\n",
        "            n_val = max(1, int(n_total * VAL_FRAC_IN_TRAIN))\n",
        "            if n_total - n_val < 1:\n",
        "                print(f\"[Fold {f_idx+1}] SKIP (train too small after val split).\")\n",
        "                fold_stats.append(None)\n",
        "                continue\n",
        "\n",
        "            real_train_idx = train_indices[:-n_val]\n",
        "            val_idx        = train_indices[-n_val:]\n",
        "\n",
        "            y_train = targets_mmHg[np.array(real_train_idx)]\n",
        "            scaler = LabelScaler2D(mode=\"minmax\", eps=1e-6).fit(y_train)\n",
        "\n",
        "            train_loader = DataLoader(Subset(ds, real_train_idx), batch_size=BATCH_SIZE, shuffle=True)\n",
        "            val_loader   = DataLoader(Subset(ds, val_idx), batch_size=BATCH_SIZE, shuffle=False)\n",
        "            test_loader  = DataLoader(Subset(ds, test_indices), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "            t0 = time.time()\n",
        "            model = train_one_model(train_loader, val_loader, scaler)\n",
        "            stat = eval_mae_sd_mmHg(model, test_loader, scaler)\n",
        "            elapsed = time.time() - t0\n",
        "\n",
        "            stat.update({\n",
        "                \"fold\": f_idx + 1,\n",
        "                \"block_gap_min\": bg_min,\n",
        "                \"train_n\": len(real_train_idx),\n",
        "                \"val_n\": len(val_idx),\n",
        "                \"test_n\": len(test_indices),\n",
        "                \"elapsed_s\": float(elapsed),\n",
        "            })\n",
        "            fold_stats.append(stat)\n",
        "\n",
        "            print(f\"\\n[Fold {f_idx+1}] fold=({fold_start},{fold_end}) | train=({train_start},{train_end}) | test=({test_start},{test_end})\")\n",
        "            print(f\"  sizes Train/Val/Test: {len(real_train_idx)}/{len(val_idx)}/{len(test_indices)}\")\n",
        "            print(f\"  SBP: MAE={stat['mae_sbp']:.4f} | SD={stat['sd_sbp']:.4f}\")\n",
        "            print(f\"  DBP: MAE={stat['mae_dbp']:.4f} | SD={stat['sd_dbp']:.4f}\")\n",
        "            print(f\"  elapsed: {elapsed:.1f}s\")\n",
        "\n",
        "        valid = [fs for fs in fold_stats if fs is not None and np.isfinite(fs[\"mae_sbp\"])]\n",
        "\n",
        "        print(f\"\\n--- BlockGap {bg_min} min SUMMARY ---\")\n",
        "        print(f\"ValidFolds: {len(valid)}/{N_FOLDS}\")\n",
        "\n",
        "        if len(valid) == 0:\n",
        "            print(\"No valid folds.\")\n",
        "        else:\n",
        "            summ = summarize_folds(valid)\n",
        "            print(f\"Avg   SBP: MAE={summ['avg_mae_sbp']:.4f} | SD={summ['avg_sd_sbp']:.4f}\")\n",
        "            print(f\"Avg   DBP: MAE={summ['avg_mae_dbp']:.4f} | SD={summ['avg_sd_dbp']:.4f}\")\n",
        "            print(f\"Worst SBP: MAE={summ['worst_mae_sbp']:.4f} |  StdAcrossFolds(MAE)={summ['std_mae_sbp']:.4f}\")\n",
        "            print(f\"Worst DBP: MAE={summ['worst_mae_dbp']:.4f} |  StdAcrossFolds(MAE)={summ['std_mae_dbp']:.4f}\")\n",
        "\n",
        "        print(f\"Elapsed for this BlockGap: {time.time() - t_bg0:.1f}s\")\n",
        "\n",
        "    print(f\"\\n[Phase4 Done] Total elapsed: {time.time() - t_global0:.1f}s\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_phase4_blockgap_sweep()\n"
      ]
    }
  ]
}